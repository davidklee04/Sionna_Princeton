import logging


import numpy as np
import torch
from PIL import Image
from functools import lru_cache
from functools import partial
from itertools import repeat
from multiprocessing import Pool
from os import listdir
from os.path import splitext, isfile, join
from pathlib import Path
from torch.utils.data import Dataset
from tqdm import tqdm





import os
import sys
#parent_dir_name = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
sys.path.append("/home/yl826/3DPathLoss/nc_raytracing/POC")
import CBRSUtils

from scipy.constants import speed_of_light
import numpy as np
import matplotlib.pyplot as plt

import math
import os

from scipy import ndimage

import subprocess
import concurrent
from concurrent.futures import wait
import os
from os.path import join, dirname
import random

NUM_OF_POINTS = 1000
AREA_SIZE = 512
RESOLUTION = 4
IMAGE_SIZE = int(AREA_SIZE / RESOLUTION)


class RTDataset_data_aug(Dataset):
    def __init__(self, subset, data_aug: bool = False, data_linear_aug: bool = False):
        self.subset = subset
        self.data_aug = data_aug
        self.data_linear_aug = data_linear_aug

    def __getitem__(self, index):


        building_height_arr, tx_position_channel, path_loss_heat_map, ground_truth_arr, name, ss_num, transfer_learning_input = self.subset[index]

        if self.data_aug:
            random_flip_option = random.choice([0, 1, 2, 3])
            building_height_arr = np.rot90(building_height_arr, k=random_flip_option)
            tx_position_channel = np.rot90(tx_position_channel, k=random_flip_option)
            path_loss_heat_map = np.rot90(path_loss_heat_map, k=random_flip_option)
            ground_truth_arr = np.rot90(ground_truth_arr, k=random_flip_option)
            if transfer_learning_input is not None:
                transfer_learning_input = np.rot90(transfer_learning_input, k=random_flip_option)


            # mirror_option = random.choice([0, 1])
            # if mirror_option == 1:
            #     building_height_arr = np.fliplr(building_height_arr)
            #     tx_position_channel = np.fliplr(tx_position_channel)
            #     path_loss_heat_map = np.fliplr(path_loss_heat_map)

        sparse_ss_arr = None
        sparse_ss_map = None
        if ss_num != 0:
            random_num_ss = random.randint(0,ss_num+1)
            #random_num_ss = ss_num
            res = []
            ss_map = np.full((128, 128), -160)
            while len(res) < random_num_ss:
                pos = np.random.uniform(0, building_height_arr.shape[0] - 1, size=2)
                # Using floor+1 instead of ceil to avoid int value cause ceil and floor to give the same result.
                neighbours_pos = {
                    "top_left": [math.floor(pos[0]), math.floor(pos[1])],
                    "top_right": [math.floor(pos[0]), math.floor(pos[1]) + 1],
                    "bottom_left": [math.floor(pos[0]) + 1, math.floor(pos[1])],
                    "bottom_right": [math.floor(pos[0]) + 1, math.floor(pos[1]) + 1]
                }
                weight = []
                db_linear = []
                for key, value in neighbours_pos.items():
                    # 0 means blocking by building, nan is generated by Sionna's buggy implementation of diffraction
                    if not np.isnan(ground_truth_arr[value[0]][value[1]]) and ground_truth_arr[value[0]][value[1]] != 0:
                        db_linear.append(ground_truth_arr[value[0]][value[1]])
                        weight.append(math.dist(pos, value))
                # If all four neighbours are blocked by buildings, skip
                if not weight:
                    continue
                else:
                    ss_db = 10 * np.log10(np.average(db_linear, weights=1 / np.array(weight)))
                    res.append([*pos, ss_db])
                    xx = math.floor(pos[0])
                    yy = math.floor(pos[1])
                    ss_map[xx][yy] = ss_db
                    

                    # assert np.isinf(res[-1][-1]) or np.isnan(res[-1][-1]), "Down sampling value contains nan or inf: weight:{} \n db_linear: {} \n res[-1]: {} \n {}\n {}\n {}".format( db_linear, weight, res[-1], np.isinf(res[-1][-1]), np.isnan(res[-1][-1]), np.isinf(res[-1][-1]) or np.isnan(res[-1][-1]))
            sparse_ss_arr = np.array(res)
            sparse_ss_map = ss_map

        ground_truth_arr = 10 * np.log10(ground_truth_arr)

        # ground_truth_arr[ground_truth_arr == np.nan] = -160
        ground_truth_arr[ground_truth_arr == -np.inf] = -160
        ground_truth_arr = np.nan_to_num(ground_truth_arr, nan=0)
        ground_truth_arr[ground_truth_arr >= 0] = 0
        ground_truth_arr[ground_truth_arr <= -160] = -160

        if self.data_linear_aug:
                random_a = random.uniform(0.1, 0.7)


                # random_b = random.uniform(-20, -100)

                random_Ptx = random.uniform(10, 35)
                random_Gtx = random.uniform(10, 20)
                random_Grx = random.uniform(-10, 10)
                random_IL = random.uniform(-10, -20)

                random_b = -1 * (random_Ptx + random_Gtx + random_Grx + random_IL)

                ground_truth_arr = np.where(ground_truth_arr != -160, ground_truth_arr * random_a + random_b, -160)
                #sparse_ss_arr[:,2] = sparse_ss_arr[:,2] * random_a + random_b

                sparse_ss_map = np.where(sparse_ss_map != -160, sparse_ss_map * random_a + random_b, -160)
                if transfer_learning_input is not None:
                    transfer_learning_input = np.where(transfer_learning_input != -160, transfer_learning_input * random_a + random_b, -160)


        combined_input = np.zeros((3, IMAGE_SIZE, IMAGE_SIZE), dtype=float)

        # Combine all the channels together

        combined_input[0, :, :] = building_height_arr
        #combined_input[0, :, :] = np.zeros(building_height_arr.shape)
        combined_input[1, :, :] = tx_position_channel
        combined_input[2, :, :] = path_loss_heat_map
        

        sparse_ss_arr = np.zeros((ss_num,3))
        if transfer_learning_input is not None:
            combined_input[1, :, :] = sparse_ss_map
            combined_input[2, :, :] = transfer_learning_input

        return {
            'combined_input': torch.as_tensor(combined_input.copy()).float().contiguous(),
            'ground_truth': torch.as_tensor(ground_truth_arr.copy()).long().contiguous(),
            'file_name': name,
            'sparse_ss': torch.as_tensor(sparse_ss_arr.copy()).float().contiguous()
        }

    def __len__(self):
        return len(self.subset)


class RTDataset(Dataset):
    def __init__(self, building_height_map_dir: str, terrain_height_map_dir: str,
                 ground_truth_signal_strength_map_dir: str, sparse_ss_dir: str, pathloss: bool = False,
                 median_filter_size: int = 0, transform=None, ss_num=0, transfer_learning_input=None):

        np.seterr(divide='ignore')
        self.building_height_map_dir = Path(building_height_map_dir)
        self.terrain_height_map_dir = Path(terrain_height_map_dir)
        self.ground_truth_signal_strength_map_dir = Path(ground_truth_signal_strength_map_dir)

        self.sparse_ss_dir = Path(sparse_ss_dir)

        self.pathloss = pathloss
        self.ss_num = ss_num

        self.median_filter_size = median_filter_size
        self.transfer_learning_input = transfer_learning_input

        ids_gt = [splitext(file)[0] for file in listdir(self.ground_truth_signal_strength_map_dir) if
                  isfile(join(self.ground_truth_signal_strength_map_dir, file)) and not file.startswith(
                      '.')]
        
        if self.transfer_learning_input is not None:
            self.ids_transfer_gt = [splitext(file)[0] for file in listdir(self.transfer_learning_input) if
                  isfile(join(self.transfer_learning_input, file)) and not file.startswith(
                      '.')]
        ids_building = [splitext(file)[0].split("_")[0] for file in listdir(self.building_height_map_dir) if
                        isfile(join(self.building_height_map_dir, file)) and not file.startswith(
                            '.')]
        # ids_terrain = [splitext(file)[0].split("_")[0] for file in listdir(self.terrain_height_map_dir) if
        #                isfile(join(self.terrain_height_map_dir, file)) and not file.startswith(
        #                    '.')]

        self.ids = ids_gt
        

        # Here is a workaround of tf variable length length in a single bath problem
        filtered_ids = []
        # for file in tqdm(ids_gt, desc="Checking sparse points size"):
        #     # tmp = np.load(os.path.join(self.sparse_ss_dir, file.split("\\")[-1] + ".npy"))
        #     # # print(tmp.shape)
        #     #
        #     # if len(tmp) >= NUM_OF_POINTS:
        #     # filtered_ids.append(file)
        max_gt_value = 0
        min_gt_value = 10000


        for file in tqdm(ids_gt, desc="Checking Building Arr size"):
            name_splited = file.split("_")
            tmp =  np.load(
            os.path.join(self.building_height_map_dir, name_splited[0] + "_" + name_splited[1] + ".npy"))

            # print(tmp.shape)

            if tmp.shape == (1000, 1000):
                filtered_ids.append(file)
            else:
                print("Building Arr size is not enough")
                print(tmp.shape)
            # if np.max(tmp) > max_gt_value:
            #     max_gt_value = np.max(tmp)
            # if np.min(tmp) < min_gt_value:
            #     min_gt_value = np.min(tmp)
            
        print("max ground truth value: ", 10 * np.log10(max_gt_value))
        print("min ground truth value: ", 10 * np.log10(min_gt_value))
        self.ids = filtered_ids
        if not self.ids:
            raise RuntimeError(
                f'No input file found in {self.ground_truth_signal_strength_map_dir}, make sure you put your images there')

    def __len__(self):
        return len(self.ids)

    def get_ids(self):
        return self.ids

    def __getitem__(self, idx):

        name = self.ids[idx]

        name_splited = name.split("_")
        file_name_id_part = name_splited[0]
        tx_height = name_splited[-1]


        # Ori position
        # tx_x = int(name_splited[-3]) + 500
        # tx_y = (-1 * int(name_splited[-2])) + 500
        tx_x = int(name_splited[2]) + 500
        tx_y = (-1 * int(name_splited[3])) + 500
        tx_position = [tx_x // 10, tx_y // 10]
        distance = np.arange(0, 1450, 1)
        path_loss_res = CBRSUtils.CBRSUtils.pathloss_38901(distance, 3.60, h_bs=int(tx_height), h_ut=2)

        # Ori image size 1040 * 1040, crop to 1000 * 1000
        # building_height_arr = np.load(os.path.join(self.building_height_map_dir, name_splited[0]+"_"+name_splited[1]+".npy"))[4:104,4:104]

        # Ori image size 1000*1000
        building_height_arr = np.load(
            os.path.join(self.building_height_map_dir, name_splited[0] + "_" + name_splited[1] + ".npy"))

        # Crop to 512*512 based on location information coded in the file name.
        building_height_arr = building_height_arr[tx_y - 256:tx_y + 256, tx_x - 256:tx_x + 256]

        # Resize to 128*128 based on the resolution of 4m.
        building_height_arr = building_height_arr[::4, ::4]

        ground_truth_arr = np.load(os.path.join(self.ground_truth_signal_strength_map_dir, name + ".npy"))

        if self.median_filter_size != 0:
            ground_truth_arr = ndimage.median_filter(ground_truth_arr, size=self.median_filter_size)

        # Construct the TX position channel
        tx_position_channel = np.full((IMAGE_SIZE, IMAGE_SIZE), 0, dtype=int)

        # Base station position channel
        # tx_position_channel[tx_position[1]][tx_position[0]] = tx_height

        tx_position_channel[63, 63] = tx_height

        # Construct the Path Loss Model (3GPP TR 308.91 nLos UMa)
        path_loss_heat_map = np.full((IMAGE_SIZE, IMAGE_SIZE), 0, dtype=float)

        for row in range(path_loss_heat_map.shape[0]):
            for col in range(path_loss_heat_map.shape[1]):
                # Compute the distance between pixel and tx
                dist = math.sqrt((63 * RESOLUTION - row * RESOLUTION) ** 2 + (63 * RESOLUTION - col * RESOLUTION) ** 2)
                tmp = -1 * path_loss_res[int(dist)]
                if np.isinf(tmp):
                    tmp = -50.0
                    # print("Got inf in PL with index: ",row, col)
                path_loss_heat_map[row][col] = tmp

            # Legacy implementation of loading sparse_ss_arr
            # sparse_ss_arr = np.load(os.path.join(self.sparse_ss_dir, name+".npy"))
            # sparse_ss_arr = sparse_ss_arr[~np.any(np.isnan(sparse_ss_arr), axis=1)]
            # sparse_ss_arr = sparse_ss_arr[~np.any(np.isinf(sparse_ss_arr), axis=1)]
            # choice = np.random.choice(len(sparse_ss_arr), NUM_OF_POINTS, replace=False)
            # sparse_ss_arr = sparse_ss_arr[choice, :]
            #
            # if (sparse_ss_arr[:,2] < -160).any():
            #     print("Fucked Inputs EXIT!")
            #     print( np.where(sparse_ss_arr[:,2]<-160))
            #     for idx in np.where(sparse_ss_arr[:,2]<-160):
            #         print(idx, sparse_ss_arr[idx,2])

            # Load sparse_ss directly from ground truth:

        # sparse_ss_arr[:,2] = 10 * np.log10(sparse_ss_arr[:,2])

        # Convert the linear power to dB scale


        # Since right now GT.size is 100*100 and other two size is 1000 * 1000, just check the input.
        # assert building_height_arr.shape == terrain_height_aimport loggin

        #         if np.isinf(combined_input).any() or np.isnan(combined_input).any():

        #             print("this is 63,63 ", combined_input[2,63,63])

        #             #print(combined_input)
        #             print("Fucked! inputs problem!")
        #             exit()

        if self.transfer_learning_input:
            last_underscore_index = name.rfind('_')
            second_last_underscore_index = name.rfind('_', 0, last_underscore_index)
            for tmp_idx in range(len(self.ids_transfer_gt)):
                if self.ids_transfer_gt[tmp_idx].startswith(name[:second_last_underscore_index]):
                    return building_height_arr, tx_position_channel, path_loss_heat_map, ground_truth_arr, name, self.ss_num ,np.load(os.path.join(self.transfer_learning_input,  self.ids_transfer_gt[tmp_idx] + ".npy"))


        return building_height_arr, tx_position_channel, path_loss_heat_map, ground_truth_arr, name, self.ss_num ,None


if __name__ == '__main__':
    building_height_map_dir = Path('../../res/Bl_building_npy')
    terrain_height_map_dir = Path('../../res/Bl_terrain_npy')
    ground_truth_signal_strength_map_dir = Path('./coverage_maps')
    sparse_ss_dir = Path('/home/yl826/3DPathLoss/nc_raytracing/jul18_sparse')
    dataset = RTDataset(building_height_map_dir, terrain_height_map_dir, ground_truth_signal_strength_map_dir)
